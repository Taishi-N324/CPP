{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkNmR+tTY9Bs6CopTBKmXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taishi-N324/CPP/blob/main/t5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8cKZ8j7BZvK",
        "outputId": "1fe87e40-01b7-4fe2-d5e3-fa112ee1f12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.11.0\n",
            "tcmalloc: large alloc 1412186112 bytes == 0x3666000 @  0x7ff90b4be1e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n",
            "tcmalloc: large alloc 1412186112 bytes == 0x5792a000 @  0x7ff90b4be1e7 0x4a3940 0x5b438c 0x64cfe7 0x59b076 0x515655 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6\n",
            "tcmalloc: large alloc 1412186112 bytes == 0xabbee000 @  0x7ff90b4be1e7 0x4a3940 0x59b5e2 0x63a515 0x63bd66 0x63be16 0x59afff 0x515655 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6\n",
            "tcmalloc: large alloc 1765236736 bytes == 0x5792a000 @  0x7ff90b4bf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x593fce\n",
            "  Using cached https://download.pytorch.org/whl/rocm4.5.2/torch-1.11.0%2Brocm4.5.2-cp37-cp37m-linux_x86_64.whl (1412.2 MB)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: torchaudio==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "tcmalloc: large alloc 1891401728 bytes == 0x5dcba000 @  0x7ff90b4bf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x593fce\n",
            "  Using cached https://download.pytorch.org/whl/rocm4.3.1/torch-1.11.0%2Brocm4.3.1-cp37-cp37m-linux_x86_64.whl (1513.1 MB)\n",
            "tcmalloc: large alloc 2138439680 bytes == 0x3b9c000 @  0x7ff90b4be1e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n",
            "tcmalloc: large alloc 2673049600 bytes == 0x3b9c000 @  0x7ff90b4bf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x593fce\n",
            "  Using cached https://download.pytorch.org/whl/cu115/torch-1.11.0%2Bcu115-cp37-cp37m-linux_x86_64.whl (2138.4 MB)\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n",
            "  Using cached https://download.pytorch.org/whl/cu102/torch-1.11.0%2Bcu102-cp37-cp37m-linux_x86_64.whl (750.6 MB)\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torch-1.11.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (169.1 MB)\n",
            "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[31mERROR: Cannot install torch==1.11.0 and torchvision==0.10.0+cu111 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.11.0\n",
            "    torchvision 0.10.0+cu111 depends on torch==1.9.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers[ja] in /usr/local/lib/python3.7/dist-packages (4.19.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (0.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (2.23.0)\n",
            "Requirement already satisfied: unidic-lite>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (1.0.8)\n",
            "Requirement already satisfied: unidic>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (1.1.0)\n",
            "Requirement already satisfied: fugashi>=1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (1.1.2)\n",
            "Requirement already satisfied: ipadic<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.9.0+cu111)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.1.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.28)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[ja]) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[ja]) (3.0.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.4.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from unidic>=1.0.2->transformers[ja]) (0.9.1)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from unidic>=1.0.2->transformers[ja]) (1.1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (1.24.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (2.1.2)\n",
            "Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[ja]) (3.8.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.3.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (1.8.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (1.5.0)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (2.1.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (22.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (5.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter) (21.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->qtpy>=2.0.1->qtconsole->jupyter) (3.0.8)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install torch==1.11.0 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install transformers[\"ja\"] numpy pandas sentencepiece fairseq\n",
        "!pip install -U jupyter ipywidgets \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fEVZna2gD5IF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://nlp.stanford.edu/projects/jesc/data/split.tar.gz\"\n",
        "!tar -zxvf split.tar.gz\n",
        "!ls split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxtC71USBipP",
        "outputId": "35d2c416-bc47-477f-98f9-4d8d3e2a464e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 05:50:44--  https://nlp.stanford.edu/projects/jesc/data/split.tar.gz\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102198329 (97M) [application/x-gzip]\n",
            "Saving to: ‘split.tar.gz.2’\n",
            "\n",
            "split.tar.gz.2      100%[===================>]  97.46M  27.4MB/s    in 5.5s    \n",
            "\n",
            "2022-05-15 05:50:49 (17.9 MB/s) - ‘split.tar.gz.2’ saved [102198329/102198329]\n",
            "\n",
            "split/\n",
            "split/train\n",
            "split/dev\n",
            "split/test\n",
            "dev  test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for line in open('split/train', 'r', encoding='utf-8'):\n",
        "    text = line.split('\\t')\n",
        "    text = [t.rstrip('\\n') for t in text]\n",
        "    res.extend(text)\n",
        "for line in open('split/dev', 'r', encoding='utf-8'):\n",
        "    text = line.split('\\t')\n",
        "    text = [t.rstrip('\\n') for t in text]\n",
        "    res.extend(text)\n",
        "for line in open('split/test', 'r', encoding='utf-8'):\n",
        "    text = line.split('\\t')\n",
        "    text = [t.rstrip('\\n') for t in text]\n",
        "    res.extend(text)\n",
        "\n",
        "print(len(res))\n",
        "with open('tmp.txt', 'w') as f:\n",
        "    for d in res:\n",
        "        f.write(\"%s\\n\" % d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fBfPXFABjTB",
        "outputId": "965f329f-c13a-4cf8-ddbf-680d581f3642"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5602776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail tmp.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCzcNwawBlzQ",
        "outputId": "69440594-0deb-4934-bd09-df39663f16cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am i free to go?\n",
            "行っていいのですか?\n",
            "you'll definitely become a good nurse.\n",
            "あんた きっと いい看護師になるよ。\n",
            "and isn't that what your facemash was about?\n",
            "フェイスマッシュも同じだ\n",
            "what is it this time?\n",
            "ロケットパンチ止めようとしてんぞ! どういう状況だ? これ!\n",
            "you poured your father's remains in and closed it.\n",
            "一度 封をはがして灰を入れ また封をしても―\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib7Br92_DQ5A",
        "outputId": "b588ee24-4ca5-448f-ed5c-64c025a23f8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece "
      ],
      "metadata": {
        "id": "cshT9JRxBpOI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentencepiece.SentencePieceTrainer.Train(\"--input=tmp.txt --model_prefix=new_spm_model --vocab_size=10000 --vocabulary_output_piece_score=false --model_type=bpe\")"
      ],
      "metadata": {
        "id": "z0t7Xo8bBpuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\"\n",
        "!tar -zxvf mbart.cc25.v2.tar.gz\n",
        "!ls mbart.cc25.v2"
      ],
      "metadata": {
        "id": "YmtosJduBweG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edited = []\n",
        "for line in open(\"new_spm_model.vocab\", 'r', encoding='utf-8'):\n",
        "    if line in [\"<unk>\\n\", \"<s>\\n\", \"</s>\\n\"]:\n",
        "        continue\n",
        "    new_line = line.rstrip('\\n') + \" 1\\n\"\n",
        "    edited.append(new_line)\n",
        "\n",
        "with open('new_dict.txt', 'w') as f:\n",
        "    for e in edited:\n",
        "        f.write(e)"
      ],
      "metadata": {
        "id": "ql9o7JsjB3cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir reduced_model\n",
        "!ls"
      ],
      "metadata": {
        "id": "RNyi6IxNB6bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fairseq.data import Dictionary\n",
        "from transformers import (\n",
        "    MBartForConditionalGeneration, MBartTokenizer, MBartConfig\n",
        ")\n",
        "from typing import List\n",
        "import torch"
      ],
      "metadata": {
        "id": "AVxlwMwdB7Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langs = [\n",
        "    \"ar_AR\",\n",
        "    \"cs_CZ\",\n",
        "    \"de_DE\",\n",
        "    \"en_XX\",\n",
        "    \"es_XX\",\n",
        "    \"et_EE\",\n",
        "    \"fi_FI\",\n",
        "    \"fr_XX\",\n",
        "    \"gu_IN\",\n",
        "    \"hi_IN\",\n",
        "    \"it_IT\",\n",
        "    \"ja_XX\",\n",
        "    \"kk_KZ\",\n",
        "    \"ko_KR\",\n",
        "    \"lt_LT\",\n",
        "    \"lv_LV\",\n",
        "    \"my_MM\",\n",
        "    \"ne_NP\",\n",
        "    \"nl_XX\",\n",
        "    \"ro_RO\",\n",
        "    \"ru_RU\",\n",
        "    \"si_LK\",\n",
        "    \"tr_TR\",\n",
        "    \"vi_VN\",\n",
        "    \"zh_CN\"\n",
        "]\n",
        "\n",
        "def load_dict(langs: List[str], path: str) -> Dictionary:\n",
        "    d = Dictionary.load(path)\n",
        "    for ll in langs:\n",
        "        d.add_symbol(f\"[{ll}]\")\n",
        "    d.add_symbol(\"<mask>\")\n",
        "    d.add_symbol(\"<pad>\")\n",
        "    return d\n",
        "\n",
        "\n",
        "pre_dict = load_dict(langs, \"./mbart.cc25.v2/dict.txt\")\n",
        "ft_dict = load_dict(langs, \"./new_dict.txt\")\n",
        "\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-cc25\")\n",
        "org_sd = model.state_dict()\n",
        "resized_sd = model.state_dict()\n",
        "\n",
        "mapping: List[int] = []\n",
        "for i in range(len(ft_dict)):\n",
        "    word = ft_dict[i]\n",
        "    mapping.append(pre_dict.index(word))\n",
        "\n",
        "for name in [\"model.encoder.embed_tokens.weight\", \"model.decoder.embed_tokens.weight\", \"model.shared.weight\", \"lm_head.weight\"]:\n",
        "    pre_tensor: torch.Tensor = org_sd[name]\n",
        "    ft_tensor = torch.zeros(\n",
        "        [len(ft_dict), 1024], dtype=pre_tensor.dtype, layout=pre_tensor.layout, device=pre_tensor.device,\n",
        "    )\n",
        "    for ft_i, pre_i in enumerate(mapping):\n",
        "        ft_tensor[ft_i] = pre_tensor[pre_i]\n",
        "    resized_sd[name] = ft_tensor\n",
        "resized_sd[\"final_logits_bias\"] = resized_sd[\"final_logits_bias\"][:, :len(ft_dict)]\n",
        "\n",
        "config = MBartConfig.from_pretrained(\"facebook/mbart-large-cc25\")\n",
        "config.vocab_size = len(ft_dict)\n",
        "print(config)\n"
      ],
      "metadata": {
        "id": "4ZqIA8LDB-xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = MBartForConditionalGeneration.from_pretrained(None, config=config, state_dict=resized_sd)\n",
        "#new_model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
        "\n",
        "#model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")"
      ],
      "metadata": {
        "id": "MpIqNSlRCCbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.save_pretrained(\"./reduced_model\")"
      ],
      "metadata": {
        "id": "xYqvXmQvCnED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls reduced_model"
      ],
      "metadata": {
        "id": "jQFcE35qDdXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\")\n",
        "\n",
        "tokenizer.save_pretrained(\"./reduced_model\")"
      ],
      "metadata": {
        "id": "2EjJnebhDk01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./new_spm_model.model ./reduced_model/sentencepiece.bpe.model\n",
        "!ls -al ./reduced_model"
      ],
      "metadata": {
        "id": "iitVt2P4Doai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"./reduced_model\")\n",
        "tokenizer = MBartTokenizer.from_pretrained(\"./reduced_model\")"
      ],
      "metadata": {
        "id": "Z-iGZK6QDuy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output"
      ],
      "metadata": {
        "id": "YmGog-HQD8ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        ")\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "result_dir = \"./output\""
      ],
      "metadata": {
        "id": "1HILo1uRECX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_collator(features: list):\n",
        "    x = [f[\"translation\"][\"ja\"] for f in features]\n",
        "    y = [f[\"translation\"][\"en\"] for f in features]\n",
        "    inputs = tokenizer(x, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=32)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        inputs['labels'] = tokenizer(y, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=48)['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenizer = MBartTokenizer.from_pretrained(\"./reduced_model\", src_lang=\"ja_XX\", tgt_lang=\"en_XX\")\n",
        "tokenizer.save_pretrained(result_dir)"
      ],
      "metadata": {
        "id": "WVjmPuDvEDAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "eval_data = []\n",
        "\n",
        "for line in open(\"./split/train\", \"r\", encoding='utf-8'):\n",
        "    text = line.split('\\t')\n",
        "    train_data.append(\n",
        "        {\"translation\": {\n",
        "            \"ja\": text[1].rstrip('\\n'),\n",
        "            \"en\": text[0].rstrip('\\n')\n",
        "        }}\n",
        "    )\n",
        "print(f\"train_data size: {len(train_data)}\")\n",
        "\n",
        "for line in open(\"./split/dev\", \"r\", encoding='utf-8'):\n",
        "    text = line.split('\\t')\n",
        "    eval_data.append(\n",
        "        {\"translation\": {\n",
        "            \"ja\": text[1].rstrip('\\n'),\n",
        "            \"en\": text[0].rstrip('\\n')\n",
        "        }}\n",
        "    )\n",
        "print(f\"eval_data size: {len(eval_data)}\")"
      ],
      "metadata": {
        "id": "5SPoGdsXEFgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 1\n",
        "learning_rate = 3e-5\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "u9SHxRfEEIjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"./reduced_model\")\n",
        "\n",
        "args = Seq2SeqTrainingArguments(output_dir=result_dir,\n",
        "                                do_train=True,\n",
        "                                do_eval=True,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                learning_rate=learning_rate,\n",
        "                                num_train_epochs=epochs,\n",
        "                                evaluation_strategy=\"epoch\",\n",
        "                                )\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model,\n",
        "                         args=args,\n",
        "                         data_collator=data_collator,\n",
        "                         train_dataset=train_data,\n",
        "                         eval_dataset=eval_data,\n",
        "                         )"
      ],
      "metadata": {
        "id": "OnaQqICRPeT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"./reduced_model\")\n",
        "\n",
        "args = Seq2SeqTrainingArguments(output_dir=result_dir,\n",
        "                                do_train=True,\n",
        "                                do_eval=True,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                learning_rate=learning_rate,\n",
        "                                num_train_epochs=epochs,\n",
        "                                evaluation_strategy=\"epoch\",\n",
        "                                )\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model,\n",
        "                         args=args,\n",
        "                         data_collator=data_collator,\n",
        "                         train_dataset=train_data,\n",
        "                         eval_dataset=eval_data,\n",
        "                         )"
      ],
      "metadata": {
        "id": "fimgrbYPEKOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer"
      ],
      "metadata": {
        "id": "WMEuYEnFNGmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model(result_dir)"
      ],
      "metadata": {
        "id": "R6FUiHVgEMdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"おはよう\"\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "translated_tokens = model.generate(**inputs, decoder_start_token_id=tokenizer.lang_code_to_id[\"en_XX\"], early_stopping=True, max_length=48)\n",
        "pred = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"日本語 - {sentence}: English - {pred}\")"
      ],
      "metadata": {
        "id": "93Zes7aXEQsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_vK3VZZUFYcc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}